{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook BYOL.ipynb to script\n",
      "[NbConvertApp] Writing 6250 bytes to BYOL.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Derek/opt/anaconda3/lib/python3.7/site-packages/torch/autocast_mode.py:162: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n",
      "/Users/Derek/Desktop/hyperbolic_byol/mobius.py:25: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  k = torch.tensor(k)\n",
      "/Users/Derek/Desktop/hyperbolic_byol/mobius.py:60: UserWarning: where received a uint8 condition tensor. This behavior is deprecated and will be removed in a future version of PyTorch. Use a boolean condition instead. (Triggered internally at  /Users/distiller/project/pytorch/aten/src/ATen/native/TensorCompare.cpp:333.)\n",
      "  res = torch.where(cond, res_0, res_c)\n",
      "/Users/Derek/opt/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 144 from C header, got 152 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/Users/Derek/opt/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 144 from C header, got 152 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/Users/Derek/opt/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 144 from C header, got 152 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/Users/Derek/opt/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 144 from C header, got 152 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to script BYOL.ipynb\n",
    "import BYOL\n",
    "import torch\n",
    "import time\n",
    "from pretrain_dataloader import *\n",
    "from pl_bolts.optimizers.lr_scheduler import LinearWarmupCosineAnnealingLR\n",
    "from utils import *\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "import torch.nn.functional as F\n",
    "torch.backends.cudnn.enabled = True\n",
    "import copy\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "args = return_default_args()\n",
    "args.batch_size = 2\n",
    "train_loader = prepare_cifar_train_loader(args)\n",
    "online = BYOL.euclidean_BYOL_module().to(device).to(memory_format=torch.channels_last)\n",
    "target = copy.deepcopy(online).to(device).to(memory_format=torch.channels_last)\n",
    "fine_to_coarse = fine_to_coarse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [\n",
    "            {\"name\": \"backbone\", \"params\": online.network.parameters()},\n",
    "            {\n",
    "                \"name\": \"classifier\",\n",
    "                \"params\": online.classifier.parameters(),\n",
    "                \"lr\": args.classifier_lr,\n",
    "                \"weight_decay\": args.classifier_weight_decay,\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"coarse_classifier\",\n",
    "                \"params\": online.coarse_classifier.parameters(),\n",
    "                \"lr\": args.classifier_lr,\n",
    "                \"weight_decay\": args.classifier_weight_decay,\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"momentum_classifier\",\n",
    "                \"params\": target.classifier.parameters(),\n",
    "                \"lr\": args.classifier_lr,\n",
    "                \"weight_decay\": args.classifier_weight_decay,\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"coarse_momentum_classifier\",\n",
    "                \"params\": target.coarse_classifier.parameters(),\n",
    "                \"lr\": args.classifier_lr,\n",
    "                \"weight_decay\": args.classifier_weight_decay,\n",
    "            },\n",
    "            {'params': online.projector.parameters()},\n",
    "            {'params':online.predictor.parameters(),}\n",
    "        ]\n",
    "\n",
    "\n",
    "args.lr = .001\n",
    "args.wd = 1.5e-5\n",
    "\n",
    "opt = torch.optim.AdamW(params, lr = args.lr, weight_decay = args.wd)\n",
    "schedule = LinearWarmupCosineAnnealingLR(\n",
    "                    opt,\n",
    "                    warmup_epochs= 10 * 195,\n",
    "                    max_epochs= 195 * 200,\n",
    "                    warmup_start_lr=3e-05,\n",
    "                    eta_min=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_step(data, online, target, fine_to_coarse = fine_to_coarse):\n",
    "    step_metrics = {}\n",
    "    \n",
    "    labels2 = []\n",
    "    for i in data[2]:\n",
    "        labels2.append(fine_to_coarse[i.item()])\n",
    "    labels2 = torch.Tensor(labels2, device = device)\n",
    "    labels2 = labels2.long()\n",
    "    \n",
    "    online1 = online(data[1][0])\n",
    "    online2 = online(data[1][1])\n",
    "    target1 = target.momentum_forward(data[1][0])\n",
    "    target2 = target.momentum_forward(data[1][1])\n",
    "    \n",
    "    #byol_loss\n",
    "    step_metrics[\"byol_loss\"] = byol_loss_func(online1['p'], target2['z'])\n",
    "    step_metrics[\"byol_loss\"] += byol_loss_func(online2['p'], target1['z'])\n",
    "    \n",
    "    #cross entropy loss\n",
    "    \n",
    "    step_metrics[\"online_cross_entropy_loss\"] = F.cross_entropy(online1['logits'], data[2], ignore_index=-1)\n",
    "    step_metrics[\"momentum_cross_entropy_loss\"] = F.cross_entropy(target1['logits'], data[2], ignore_index=-1)\n",
    "    step_metrics[\"coarse_online_cross_entropy_loss\"] = F.cross_entropy(online1['coarse_logits'], labels2, ignore_index=-1)\n",
    "    step_metrics[\"coarse_momentum_cross_entropy_loss\"] = F.cross_entropy(target1['coarse_logits'], labels2, ignore_index=-1)\n",
    "    \n",
    "    #accuracy of predictions\n",
    "    _, predicted = torch.max(online1['logits'], 1)\n",
    "    step_metrics[\"online_acc1\"] = (predicted == data[2]).sum()\n",
    "    _, predicted = torch.max(target1['logits'], 1)\n",
    "    step_metrics[\"target_acc1\"] = (predicted == data[2]).sum()\n",
    "    \n",
    "    _, pred = online1['logits'].topk(5)\n",
    "    data[2] = data[2].unsqueeze(1).expand_as(pred)\n",
    "    step_metrics[\"online_acc5\"] = (data[2] == pred).any(dim = 1).sum()\n",
    "    _, pred = target1['logits'].topk(5)\n",
    "    step_metrics[\"target_acc5\"] = (data[2] == pred).any(dim = 1).sum()\n",
    "    \n",
    "    #accuracy of predictions\n",
    "    _, predicted = torch.max(online1['coarse_logits'], 1)\n",
    "    step_metrics[\"coarse_online_acc1\"] = (predicted == labels2).sum()\n",
    "    _, predicted = torch.max(target1['coarse_logits'], 1)\n",
    "    step_metrics[\"coarse_target_acc1\"] = (predicted == labels2).sum()\n",
    "    \n",
    "    _, pred = online1['coarse_logits'].topk(5)\n",
    "    labels2 = labels2.unsqueeze(1).expand_as(pred)\n",
    "    step_metrics[\"coarse_online_acc5\"] = (labels2 == pred).any(dim = 1).sum()\n",
    "    _, pred = target1['coarse_logits'].topk(5)\n",
    "    step_metrics[\"coarse_target_acc5\"] = (labels2 == pred).any(dim = 1).sum()\n",
    "                   \n",
    "        \n",
    "    \n",
    "    \n",
    "    #metrics to track\n",
    "    with torch.no_grad():\n",
    "        online1p_softmax = F.softmax(online1['p'], dim = 1)\n",
    "        online2p_softmax = F.softmax(online2['p'], dim = 1)\n",
    "        online1rep_softmax = F.softmax(online1['Representation'], dim = 1)\n",
    "        online2rep_softmax = F.softmax(online2['Representation'], dim = 1)\n",
    "        online1z_softmax = F.softmax(online1['z'], dim = 1)\n",
    "        online2z_softmax = F.softmax(online2['z'], dim = 1)\n",
    "        \n",
    "        target1z_softmax = F.softmax(target1['z'], dim = 1)\n",
    "        target2z_softmax = F.softmax(target1['z'], dim = 1)\n",
    "        target1rep_softmax = F.softmax(target1['Representation'], dim = 1)\n",
    "        target2rep_softmax = F.softmax(target2['Representation'], dim = 1)\n",
    "        \n",
    "        \n",
    "        cross_entropy = F.cross_entropy(online1p_softmax, target2z_softmax, ignore_index=-1) + F.cross_entropy(online2p_softmax, target1z_softmax, ignore_index=-1)\n",
    "        l1_dist = F.l1_loss(online1['p'], target2['z']) + F.l1_loss(online2['p'], target1['z'])\n",
    "        l2_dist = F.mse_loss(online1['p'], target2['z']) + F.mse_loss(online2['p'], target1['z'])\n",
    "        smooth_l1 = F.smooth_l1_loss(online1['p'], target2['z']) + F.smooth_l1_loss(online2['p'], target1['z'])\n",
    "        kl_div = F.kl_div(online1p_softmax, target2z_softmax) + F.kl_div(online2p_softmax, target1z_softmax)\n",
    "        \n",
    "        representation_l1 = F.l1_loss(online1['Representation'], target2['Representation']) + F.l1_loss(online2['Representation'], target1['Representation'])\n",
    "        representation_l2 = F.mse_loss(online1['Representation'], target2['Representation']) + F.mse_loss(online2['Representation'], target1['Representation'])\n",
    "        representation_cross_entropy = F.cross_entropy(online1rep_softmax, target2rep_softmax, ignore_index=-1) + F.cross_entropy(online2rep_softmax, target1rep_softmax, ignore_index=-1)\n",
    "        representation_kl = F.kl_div(online1rep_softmax, target2rep_softmax) + F.kl_div(online2rep_softmax, target1rep_softmax)\n",
    "        representation_cos_sim = F.cosine_similarity(online1['Representation'], target2['Representation']) + F.cosine_similarity(online2['Representation'], target1['Representation'])\n",
    "\n",
    "        projection_l1 = F.l1_loss(online1['z'], target2['z']) + F.l1_loss(online2['z'], target1['z'])\n",
    "        projection_l2 = F.mse_loss(online1['z'], target2['z']) + F.mse_loss(online2['z'], target1['z'])\n",
    "        projection_cross_entropy = F.cross_entropy(online1z_softmax, target2z_softmax, ignore_index=-1) + F.cross_entropy(online2z_softmax, target1z_softmax, ignore_index=-1)\n",
    "        projection_kl = F.kl_div(online1z_softmax, target2z_softmax) + F.kl_div(online2z_softmax, target1z_softmax)\n",
    "        projection_cos_sim = F.cosine_similarity(online1['z'], target2['z']) + F.cosine_similarity(online2['z'], target1['z'])\n",
    "\n",
    "        momentum_projection_cos_sim = F.cosine_similarity(target1['z'], target2['z'])\n",
    "        momentum_representation_cos_sim = F.cosine_similarity(target1['Representation'], target2['Representation'])\n",
    "        momentum_representation_l2 =  F.mse_loss(target1['Representation'], target2['Representation'])\n",
    "        momentum_projection_l2 =  F.mse_loss(target1['z'], target2['z'])\n",
    "\n",
    "        online_projection_cos_sim = F.cosine_similarity(online1['z'], online2['z'])\n",
    "        online_representation_cos_sim = F.cosine_similarity(online1['Representation'], online2['Representation'])\n",
    "        online_representation_l2 =  F.mse_loss(online1['Representation'], online2['Representation'])\n",
    "        online_projection_l2 =  F.mse_loss(online1['z'], online2['z'])\n",
    "        \n",
    "        online_representation_std = torch.mean(torch.std(online1['Representation']))\n",
    "        online_projection_std = torch.mean(torch.std(online1['z']))\n",
    "        online_prediction_std = torch.mean(torch.std(online1['p']))\n",
    "        target_representation_std = torch.mean(torch.std(target1['Representation']))\n",
    "        target_projection_std = torch.mean(torch.std(target1['z']))\n",
    "\n",
    "        step_metrics.update({\n",
    "            \"train_feats_cross_entropy\": cross_entropy,\n",
    "            \"train_feats_l1_dist\": l1_dist,\n",
    "            \"train_feats_l2_dist\": l2_dist,\n",
    "            \"train_feats_smooth_l1\": smooth_l1,\n",
    "            \"train_feats_kl_div\": kl_div,\n",
    "            \"representation_l1\": representation_l1,\n",
    "            \"representation_l2\": representation_l1,\n",
    "            \"representation_cross_entropy\": representation_cross_entropy,\n",
    "            \"representation_kl\": representation_kl,\n",
    "            \"representation_cos_sim\": representation_cos_sim.mean(),\n",
    "            \"projection_l1\": projection_l1,\n",
    "            \"projection_l2\": projection_l2,\n",
    "            \"projection_cross_entropy\": projection_cross_entropy,\n",
    "            \"projection_kl\": projection_kl,\n",
    "            \"projection_cos_sim\": projection_cos_sim.mean(),\n",
    "            \"momentum_projection_cos_sim\": momentum_projection_cos_sim.mean(),\n",
    "            \"momentum_representation_cos_sim\": momentum_representation_cos_sim.mean(),\n",
    "            \"momentum_representation_l2\": momentum_representation_l2,\n",
    "            \"momentum_representation_l2\": momentum_projection_l2,\n",
    "            \"online_projection_cos_sim\": online_projection_cos_sim.mean(),\n",
    "            \"online_representation_cos_sim\": online_representation_cos_sim.mean(),\n",
    "            \"online_representation_l2\": online_representation_l2,\n",
    "            \"online_projection_l2\": online_projection_l2,\n",
    "            \"online_representation_std\": online_representation_std,\n",
    "            \"online_projection_std\": online_projection_std,\n",
    "            \"online_prediction_std\": online_prediction_std,\n",
    "            \"target_representation_std\": target_representation_std,\n",
    "            \"target_projection_std\": target_projection_std,\n",
    "            })\n",
    "        \n",
    "        \n",
    "    return step_metrics[\"byol_loss\"] + step_metrics[\"online_cross_entropy_loss\"] + \\\n",
    "            step_metrics[\"momentum_cross_entropy_loss\"], step_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"log = True\\nname = 'BYOL - Adam Coarse'\\nif log:\\n    wandb.init(config = args.__dict__, name = name, project = 'hyperbolic_byol')\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''log = True\n",
    "name = 'BYOL - Adam Coarse'\n",
    "if log:\n",
    "    wandb.init(config = args.__dict__, name = name, project = 'hyperbolic_byol')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "0 20.48 13.0625 3.5625 0.0 0.0\n"
     ]
    }
   ],
   "source": [
    "step = 0\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "for e in range(200):\n",
    "    metrics = {\n",
    "        \"byol_loss\": 0,\n",
    "        'online_cross_entropy_loss': 0,\n",
    "        'momentum_cross_entropy_loss': 0,\n",
    "        'coarse_online_cross_entropy_loss': 0,\n",
    "        'coarse_momentum_cross_entropy_loss': 0,\n",
    "        'online_acc1': 0,\n",
    "        'target_acc1': 0,\n",
    "        'online_acc5': 0,\n",
    "        'target_acc5': 0,\n",
    "        'coarse_online_acc1': 0,\n",
    "        'coarse_target_acc1': 0,\n",
    "        'coarse_online_acc5': 0,\n",
    "        'coarse_target_acc5': 0,\n",
    "        \"train_feats_cross_entropy\": 0,\n",
    "        \"train_feats_l1_dist\": 0,\n",
    "        \"train_feats_l2_dist\": 0,\n",
    "        \"train_feats_smooth_l1\": 0,\n",
    "        \"train_feats_kl_div\": 0,\n",
    "        \"representation_l1\": 0,\n",
    "        \"representation_l2\": 0,\n",
    "        \"representation_cross_entropy\": 0,\n",
    "        \"representation_kl\": 0,\n",
    "        \"representation_cos_sim\": 0,\n",
    "        \"projection_l1\": 0,\n",
    "        \"projection_l2\": 0,\n",
    "        \"projection_cross_entropy\": 0,\n",
    "        \"projection_kl\": 0,\n",
    "        \"projection_cos_sim\": 0,\n",
    "        \"momentum_projection_cos_sim\": 0,\n",
    "        \"momentum_representation_cos_sim\": 0,\n",
    "        \"momentum_representation_l2\": 0,\n",
    "        \"momentum_representation_l2\": 0,\n",
    "        \"online_projection_cos_sim\": 0,\n",
    "        \"online_representation_cos_sim\": 0,\n",
    "        \"online_representation_l2\": 0,\n",
    "        \"online_projection_l2\": 0,\n",
    "        \"online_representation_std\": 0,\n",
    "        \"online_projection_std\": 0,\n",
    "        \"online_prediction_std\": 0,\n",
    "        \"target_representation_std\": 0,\n",
    "        \"target_projection_std\": 0,\n",
    "        }\n",
    "    \n",
    "    \n",
    "    total_loss = 0\n",
    "    now = time.time()\n",
    "    for i_, data in enumerate(train_loader):\n",
    "        \n",
    "        with torch.autocast(device):\n",
    "            step += 1\n",
    "            data[0] = data[0].to(device)\n",
    "            data[1][0] = data[1][0].to(device).to(memory_format=torch.channels_last)\n",
    "            data[1][1] = data[1][1].to(device).to(memory_format=torch.channels_last)\n",
    "            data[2] = data[2].to(device)\n",
    "            \n",
    "            \n",
    "            loss, step_metrics = training_step(data, online, target)\n",
    "            opt.zero_grad()\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(opt)\n",
    "            schedule.step()\n",
    "            scaler.update()\n",
    "            print('here')\n",
    "            update_target_params(online.network.parameters(), target.network.parameters(), .99)\n",
    "            update_target_params(online.projector.parameters(), target.projector.parameters(), .99)\n",
    "                \n",
    "        total_loss += loss\n",
    "        for key in step_metrics:\n",
    "            metrics[key] += step_metrics[key]\n",
    "        break\n",
    "    \n",
    "    print(e, round(time.time() - now, 2), total_loss.item() / (i_+1), metrics['byol_loss'].item() / (i_+1), \n",
    "          metrics['online_acc1'].item() / 50000, metrics['target_acc1'].item() / 50000)\n",
    "    break\n",
    "    if log:\n",
    "        i_ += 1\n",
    "        for key in metrics:\n",
    "            if key[-4:-1] == 'acc':\n",
    "                metrics[key] = metrics[key] / 50000\n",
    "            else:\n",
    "                metrics[key] = metrics[key]/i_\n",
    "        wandb.log(metrics)\n",
    "    checkpoint = {\n",
    "    'online': online.state_dict(),\n",
    "    'target': target.state_dict(),\n",
    "    'epoch': e,\n",
    "    'optimizer': opt.optim.state_dict()\n",
    "    }\n",
    "    torch.save(checkpoint, 'checkpoint.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'apple'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(online.state_dict(), name)\n",
    "torch.save(target.state_dict(), 'target' + name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
